- test: ep_benchmarks
  command: "build/kv_engine/ep_engine_benchmarks
                --benchmark_filter='HashTableBench'
                --benchmark_out_format=json
                --benchmark_out=benchmark_output.json &&
            python kv_engine/scripts/benchmark2xml.py
                --benchmark_file=benchmark_output.json
                --output_file=benchmark_results.xml
                --in_place --cbnt_metrics cpu_time"
  output:
    - "benchmark_results.xml"

# Note: The main purpose of the FlushVBucket bench is to measure memory usage.
#  But given that the bench flushes a fixed number of items, then we can measure
#  real_time too.
- test: ep_benchmarks
  command: "build/kv_engine/ep_engine_benchmarks
                --benchmark_filter='MemTrackingVBucketBench/FlushVBucket'
                --benchmark_out_format=json
                --benchmark_out=benchmark_output.json &&
            python kv_engine/scripts/benchmark2xml.py
                --benchmark_file=benchmark_output.json
                --output_file=benchmark_results.xml
                --in_place --cbnt_metrics real_time,PeakBytesPerItem"
  output:
    - "benchmark_results.xml"

- test: perfsuite
  command: 'build/kv_engine/ep_perfsuite -E ep -e "dbname=./ep_perfsuite.value_eviction.db" -v -f xml &&
            python kv_engine/scripts/cbnt_perfsuite_strip_results.py -d . -p output -i ".pct99" -i ".pct95"'
  output:
    - "output.2_buckets_2_threads_baseline.xml"
    - "output.With_background_DCP.xml"
    - "output.With_constant_Expiry_pager.xml"
    - "output.With_constant_defragmention.xml"

- test: perfsuite_ephemeral
  command: 'build/kv_engine/ep_perfsuite -E ep -e "bucket_type=ephemeral;dbname=./ep_perfsuite.ephemeral.db" -v -f xml &&
            python kv_engine/scripts/cbnt_perfsuite_strip_results.py -d . -p output -i ".pct99" -i ".pct95"'
  output:
    - "output.2_buckets_2_threads_baseline.xml"
    - "output.With_background_DCP.xml"
    - "output.With_constant_Expiry_pager.xml"
    - "output.With_constant_defragmention.xml"

# This following test comes from discussions with Dave Rigby: "lookup/mutation, dict/array; and with some multipath stuff in there"
# taking stability data from the existing CBNT runs to try and get the most stable set of tests possible
- test: subdoc_perf
  command: "build/kv_engine/memcached_testapp --gtest_filter='*SubdocPerfTest.Dict_RemoveBaseline/*:*SubdocPerfTest.Dict_Get/*:
            *SubdocPerfTest.Dict_Add/*:*SubdocPerfTest.Array_AddUnique/*:*SubdocPerfTest.Array_PushLast/*:
            *SubdocPerfTest.Array_ReplaceFirst_Multipath/*:*SubdocPerfTest.Array_RemoveFirst_Multipath/*' -e --gtest_output=xml"
  output:
    - "test_detail.xml"

- test: phosphor
  command: "build/phosphor/tests/benchmark/category_onoff_bench
                --benchmark_filter=/threads:
                --benchmark_out_format=json
                --benchmark_out=benchmark_output.json &&
           python kv_engine/scripts/benchmark2xml.py
                --benchmark_file=benchmark_output.json
                --output_file=benchmark_results.xml
                --in_place --cbnt_metrics cpu_time"
  output:
    - "benchmark_results.xml"

- test: ep_benchmarks
  command: "build/kv_engine/ep_engine_benchmarks
                --benchmark_filter=CheckpointBench/QueueDirtyWithManyClosedUnrefCheckpoints
                --benchmark_out_format=json
                --benchmark_out=benchmark_output.json &&
          python kv_engine/scripts/benchmark2xml.py
               --benchmark_file=benchmark_output.json
               --output_file=benchmark_results.xml
               --in_place --cbnt_metrics AvgQueueDirtyRuntime"
  output:
    - "benchmark_results.xml"
